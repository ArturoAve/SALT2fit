{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to convert from Andy's \"wstd\" LC files to SNANA format\n",
    "\n",
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User\n",
    "\n",
    "# Directory where Andy's wstd file to be converted is located:\n",
    "\n",
    "dirwstd = '/Users/arturo/Dropbox/Research/SoftwareResearch/\\\n",
    "Snoopy/AndyLCComp_2018_02/all/Wstd/tests_tmp/'\n",
    "\n",
    "DirSaveOutput = dirwstd+'snana/'\n",
    "\n",
    "# String to be printed in the 'SURVEY' line in SNANA files.\n",
    "# NOTE: For low-z CSP data set \"Survey = 'CSP' \". This allows to fit the data in \n",
    "# SNANA/SALT2 with no issues.\n",
    "# Options:\n",
    "#      'LOWZ' for low-z CfA surveys\n",
    "#      'CSP' for low-z CSP survey\n",
    "Survey = 'LOWZ'  \n",
    "\n",
    "#----------------\n",
    "\n",
    "# Filter's name matching between Andy and SNANA\n",
    "\n",
    "# Write -all- the filter's name in the line \"FILTERS: \" in the \n",
    "# SNANA-format LC file? If False, then it will be written the \n",
    "# filters listed in the list 'filterListToConvert' below. If \n",
    "# true, then it will write down -all- the filters names, for those\n",
    "# that are not in the list 'filterListToConvert' then it will\n",
    "# write the filter's name using Andy's names.\n",
    "write_all_filters = True \n",
    "\n",
    "# List of filter names that will be converted their names from Andy's \n",
    "# to SNANA convention's names.\n",
    "# Any other filter not listed here will not be written in the\n",
    "# line \"FILTERS: \" in the SNANA-like output file, \n",
    "# unless \"write_all_filters = True\".\n",
    "filterListToConvert = ['r_prime', 'i_prime', \n",
    "                       'B_CTIO1p3m','V_CTIO1p3m','R_CTIO1p3m','I_CTIO1p3m',\n",
    "                       'u_CSP', 'g_CSP', 'r_CSP', 'i_CSP', 'B_CSP', 'V_CSP']\n",
    "\n",
    "# Create a dictionary with the conversion names from above\n",
    "# The dictionary structure is: (filter_Andy: filter_SNANA)\n",
    "FilterNameConversion_dict = {}\n",
    "FilterNameConversion_dict['r_prime'] = ['r']\n",
    "FilterNameConversion_dict['i_prime'] = ['i']\n",
    "FilterNameConversion_dict['B_CTIO1p3m'] = ['B'] \n",
    "FilterNameConversion_dict['V_CTIO1p3m'] = ['V'] \n",
    "FilterNameConversion_dict['R_CTIO1p3m'] = ['R'] \n",
    "FilterNameConversion_dict['I_CTIO1p3m'] = ['I'] \n",
    "FilterNameConversion_dict['u_CSP'] = ['u']\n",
    "FilterNameConversion_dict['g_CSP'] = ['g']\n",
    "FilterNameConversion_dict['r_CSP'] = ['r']\n",
    "FilterNameConversion_dict['i_CSP'] = ['i']\n",
    "FilterNameConversion_dict['B_CSP'] = ['B']\n",
    "FilterNameConversion_dict['V_CSP'] = ['o']\n",
    "\n",
    "#--------------------------------------------\n",
    "# Rename the output files using the first 'TrimFileName' characters \n",
    "# of the datafile.\n",
    "# \"-4\" = use the full name of the file except the extension characters \".dat\"\n",
    "TrimFileName = -4 \n",
    "# TrimFileName = 18 \n",
    "\n",
    "NotebookName = '03_WstdAndy_to_SNANA.ipynb'\n",
    "\n",
    "cc = 299792.458  # Speed of light (km/s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#- Force the creation of the directory to save the outputs.\n",
    "#- \"If the subdirectory does not exist then create it\"\n",
    "import os # To use command line like instructions\n",
    "if not os.path.exists(DirSaveOutput): os.makedirs(DirSaveOutput)\n",
    "\n",
    "5+6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to identify string or number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "# Function to identify if a string is an integer number or a letter.\n",
    "# This will be used in the dictionary construction to properly read some SN names.\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Tests\n",
    "print is_number('5'), is_number('e')\n",
    "# True False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the current date and time\n",
    "import datetime \n",
    "\n",
    "# Read the time and date now\n",
    "now = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the name of this ipython notebook\n",
    "To print it in the output text files as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"NotebookName = \" + \"'\"+thename+\".ipynb\"+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"NotebookName = \" + \"'\"+thename+\".ipynb\"+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 03_WstdAndy_to_SNANA.ipynb\n"
     ]
    }
   ],
   "source": [
    "print '#', (NotebookName)\n",
    "\n",
    "# # WstdAndy_to_SNANA_v1_1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (z_helio, error_z_helio)\n",
    "# From WoodVasey & Andy Friedman metadata file.\n",
    "\n",
    "\"\"\" \n",
    "import numpy as np\n",
    "\n",
    "DirMetadata = '/Users/arturo/Dropbox/Research/SoftwareResearch/Snoopy/\\\n",
    "AndyLCComp/MyNotesAbout/'\n",
    "\n",
    "InfoSN_zHelio = np.genfromtxt(DirMetadata+\n",
    "                'WoodVasey_Andy/WoodVasey_AndyFriedman_zCMB_2017_08_11_Converted_.txt',\n",
    "                usecols=(0,1,2), dtype=['S24', float, float])\n",
    "\n",
    "# Create a dictionary: \n",
    "InfoSN_zHelio_dict ={}\n",
    "\n",
    "for i in range(len(InfoSN_zHelio)):\n",
    "    snname_int1 = InfoSN_zHelio[i][0]\n",
    "    zHelio_int1 = InfoSN_zHelio[i][1]/cc\n",
    "    err_zHelio_int1 = InfoSN_zHelio[i][2]/cc\n",
    "    \n",
    "    InfoSN_zHelio_dict[snname_int1] = [ zHelio_int1, err_zHelio_int1  ]\n",
    "    \n",
    "InfoSN_zHelio_dict['sn2006D']\n",
    "# [0.0085258982732647672, 1.6678204759907602e-05]\n",
    "\"\"\"\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (z_helio, error_z_helio, z_CMB, error_z_CMB) \n",
    "# From WoodVasey & Andy Friedman metadata file for the SPECIAL CASES\n",
    "\"\"\"\n",
    "InfoSN_zCMB_Special = np.genfromtxt(DirMetadata+'WoodVasey_Andy/WoodVasey_AndyFriedman_zCMB_2017_08_11_SpecialCases_Converted_Ho70.txt',\n",
    "                            usecols=(0,1,2, 14, 15), \n",
    "                            dtype=['S10', float, float, float, float])\n",
    "\n",
    "# Create a dictionary: \n",
    "InfoSN_zCMB_Special_dict ={}\n",
    "\n",
    "for i in range(len(InfoSN_zCMB_Special)):\n",
    "    snname_int2 = InfoSN_zCMB_Special[i][0]\n",
    "    zHelio_int2 = InfoSN_zCMB_Special[i][1]/cc\n",
    "    err_zHelio_int2 = InfoSN_zCMB_Special[i][2]/cc\n",
    "    zCMB_int2 = InfoSN_zCMB_Special[i][3]/cc\n",
    "    err_zCMB_int2 = InfoSN_zCMB_Special[i][4]/cc\n",
    "    \n",
    "    InfoSN_zCMB_Special_dict[snname_int2] = [ zHelio_int2, err_zHelio_int2, \n",
    "                                              zCMB_int2, err_zCMB_int2  ]\n",
    "    \n",
    "InfoSN_zCMB_Special_dict['sn1999cl']\n",
    "# [0.0076085970114698484,\n",
    "# 1.0006922855944561e-05,\n",
    "# 0.0031922083910463153,\n",
    "# 2.0013845711889123e-05]\n",
    "\"\"\"\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Michael Foley flow-corrected z_CMB + Cepheid distances + special cases\n",
    "# compiled by Andy Friedman\n",
    "\"\"\"\n",
    "InfoSN_zCMB_MFoley = np.genfromtxt(DirMetadata+'zCMB_FlowCorrected_MichaelFoley_original.txt',\n",
    "                            usecols=(0, 1, 2, 5), dtype=['S18', float, float, float])\n",
    "\n",
    "# Create a final dictionary: (snname: zhelio, err_zhelio, zcmb, err_zcmb, RA, DEC)\n",
    "InfoSN_dict ={}\n",
    "\n",
    "for i in range(len(InfoSN_zCMB_MFoley)):\n",
    "    snname_int3     = InfoSN_zCMB_MFoley[i][0]\n",
    "    zHelio_int3     = InfoSN_zHelio_dict[snname_int3][0]\n",
    "    err_zHelio_int3 = InfoSN_zHelio_dict[snname_int3][1]\n",
    "    RA_int  = InfoSN_zCMB_MFoley[i][1]\n",
    "    DEC_int = InfoSN_zCMB_MFoley[i][2]\n",
    "    \n",
    "    \n",
    "    #---- Define z_CMB and err_z_CMB ------\n",
    "    \n",
    "    if snname_int3 in list(InfoSN_zCMB_Special['f0']): # Special cases\n",
    "        zCMB_int3 = InfoSN_zCMB_Special_dict[snname_int3][2]\n",
    "        err_zCMB_int3 = InfoSN_zCMB_Special_dict[snname_int3][3]\n",
    "    else: # Michael Foley's zcmb values\n",
    "        zCMB_int3 = InfoSN_zCMB_MFoley[i][3]\n",
    "        err_zCMB_int3 = 150/cc\n",
    "    \n",
    "    InfoSN_dict[snname_int3] = [ zHelio_int3, err_zHelio_int3, \n",
    "                                 zCMB_int3, err_zCMB_int3, RA_int, DEC_int ]\n",
    "    \n",
    "InfoSN_dict['sn1998bu']\n",
    "# [0.0029920699339274241,\n",
    "# 1.3342563807926082e-05,\n",
    "# 0.0021141927350000001,\n",
    "# 0.0005003461427972281,\n",
    "# 161.69179,\n",
    "# 11.83531]\n",
    "\"\"\"\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0029620491653595902,\n",
       " 3.3356409519815205e-06,\n",
       " 0.0025250802006500112,\n",
       " 0.00023349486663870643,\n",
       " 0.00080722511037952796,\n",
       " 0.00050034614279722807,\n",
       " 1,\n",
       " 161.69166999999999,\n",
       " 11.835279999999999]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DirMetadata = '/Users/arturo/Dropbox/Research/SoftwareResearch/Snoopy/\\\n",
    "AndyLCComp_2018_02/'\n",
    "\n",
    "MetadataFile = 'carrick_Flow_corrections_snnames_v1.txt'\n",
    "\n",
    "# Reading the metadata file\n",
    "infoSNe_data = np.genfromtxt(DirMetadata+MetadataFile,\n",
    "                            dtype=['S17', float,float, 'S40',float,float,\n",
    "                                   float,float,float,float,'S16', int ])\n",
    "\n",
    "# Create a dictionary:\n",
    "# {snname: zhelio, e_zhel, zcmb, e_zcmb, zcmbFlow, \n",
    "#          e_zcmbFlow, code, ra, dec}\n",
    "\n",
    "InfoSN_dict = {infoSNe_data['f0'][i]: [\n",
    "                infoSNe_data['f4'][i]/cc, infoSNe_data['f5'][i]/cc,\n",
    "                infoSNe_data['f6'][i]/cc, infoSNe_data['f7'][i]/cc,\n",
    "                infoSNe_data['f8'][i]/cc, infoSNe_data['f9'][i]/cc,\n",
    "                infoSNe_data['f11'][i],\n",
    "                infoSNe_data['f1'][i], infoSNe_data['f2'][i] ]\n",
    "                for i in range(len(infoSNe_data)) }\n",
    "\n",
    "InfoSN_dict['sn1998bu']\n",
    "# [0.0029620491653595902,\n",
    "#  3.3356409519815205e-06,\n",
    "#  0.0023683050759068795,\n",
    "#  8.6726664751519533e-05,\n",
    "#  0.003138838135814611,\n",
    "#  0.00050034614279722807,\n",
    "#  1,\n",
    "#  161.69166999999999,\n",
    "#  11.835279999999999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DistanceMu_All_BeforeCutoffs.txt \n",
    "#### (for the J-band Gaussian-process Hubble diagram)\n",
    "\n",
    "Reading the 'DistanceMu_All_BeforeCutoffs.txt' from GP Hubble diagram for J band: it contains *almost* all the SNe that I need. I use the information in this file to retrieve (t_Bmax, EBV_MW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [50953.113987999997, 0.081144999999999995, 0.021700000000000001, 0.00020000000000000001]\n"
     ]
    }
   ],
   "source": [
    "DirJband = '/Users/arturo/Dropbox/Research/Articulos/10_AndyKaisey/\\\n",
    "10Compute/TheTemplates/J_band/Std_filters/4_HubbleDiagram_FlatPrior/\\\n",
    "AllSamples/Templ_AllSamples_z_gr_0/Phase-8_30_resid20_chi_1e6_EBVh0.\\\n",
    "4_Method7_MinData3_vpec150_ok/plots_HD/'\n",
    "\n",
    "# DirJband = '/Users/arturo/Dropbox/Research/Articulos/10_AndyKaisey/\\\n",
    "# 10Compute/TheTemplates/AllBands/Plots/HubbleDiagram/GaussianProcess/'\n",
    "\n",
    "DistMu_np = np.genfromtxt(DirJband+\n",
    "                          'DistanceMu_All_BeforeCutoffs_.txt',\n",
    "                             dtype=['S30',\n",
    "       float,float,float,float,float,float,float,float,float,float,\n",
    "       float,float,float,float,float,float,float,float,float,float,\n",
    "       float,float,float,float,float,float,float,float,float,float,\n",
    "       float,float,float])\n",
    "\n",
    "#----- Create a dictionary -----\n",
    "# (snname: TBmax, err_TBmax, EBV_MW, err_EBV_MW)\n",
    "\n",
    "DistMu_dict ={}\n",
    "for i in range(len(DistMu_np)):\n",
    "    \n",
    "    # Sn name\n",
    "    # Create the variable \"snName\" containing the first 8 (or 7) \n",
    "    # letters of the SNe file name\n",
    "    snname_int_1 = DistMu_np['f0'][i]\n",
    "    try:\n",
    "        if   snname_int_1[7] == '_': \n",
    "            snName_1 = snname_int_1[:7]  # To read correctly, e.g., \"sn2011B_\"\n",
    "        elif snname_int_1[7] != '_':\n",
    "            # To read correctly, e.g., \"snf20080514-002\"\n",
    "            if is_number(snname_int_1[7]): snName_1 = snname_int_1[:15] \n",
    "            else: snName_1 = snname_int_1[:8]  # To read correctly, e.g., \"sn1998bu\"  \n",
    "    except: snName_1 = snname_int_1[:6]  # To read correctly, e.g., \"sn2011B\"\n",
    "    \n",
    "    TBmax_int     = DistMu_np['f14'][i]\n",
    "    err_TBmax_int = DistMu_np['f15'][i]\n",
    "    EBV_MW_int     = DistMu_np['f23'][i]\n",
    "    err_EBV_MW_int = DistMu_np['f24'][i]\n",
    "    \n",
    "    DistMu_dict[snName_1] = [TBmax_int, err_TBmax_int, EBV_MW_int, err_EBV_MW_int]\n",
    "\n",
    "print '#', DistMu_dict['sn1998bu']\n",
    "\n",
    "# [50953.113988, 0.081145, 0.0217, 0.0002] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert fluxes to zeropoint = 27.5 (default in SNANA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test: 5874.1\n"
     ]
    }
   ],
   "source": [
    "def flux_snana(flux_old, zp_Andy): \n",
    "    \n",
    "    zp_snana = 27.5\n",
    "    flux_new = flux_old * 10**(0.4*(zp_snana - zp_Andy))\n",
    "    \n",
    "    return flux_new\n",
    "\n",
    "print '# Test:', flux_snana(587.41, 25)\n",
    "\n",
    "# Test: 5874.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read/convert Andy's wstd file to SNANA-format text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 SNe in this list\n"
     ]
    }
   ],
   "source": [
    "# Read the names of all the photometry files to be converted\n",
    "\n",
    "import glob # To read the files in my directory\n",
    "import os # To use command line like instructions\n",
    "\n",
    "os.chdir(dirwstd)\n",
    "\n",
    "#- Reading the LC data file names \n",
    "the_list = glob.glob('*.Wstd.dat')\n",
    "\n",
    "print '# %s SNe in this list'%len(the_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sn2011df__B_15_V_15_r_prime_15_i_prime_16__CfA5_challis15.Wstd.dat']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sn2011df__B_15_V_15_r_prime_15_i_prime_1\n",
      "\n",
      "# All the conversion done smoothly\n"
     ]
    }
   ],
   "source": [
    "zp_Andy = 25  # Andy's zeropoint: 25 mag \n",
    "\n",
    "for wstdFile in the_list:\n",
    "    \n",
    "    wstd_np = np.genfromtxt(dirwstd+wstdFile, usecols=[1,2,3,4,5] , \n",
    "                        dtype=[float,'S14', float, float, float])\n",
    "    \n",
    "    #====================================================\n",
    "    \n",
    "    # Create the variable \"snName\" containing the first 8 (or 7) \n",
    "    # letters of the SNe file name\n",
    "    try:\n",
    "        if   wstdFile[7] == '_': \n",
    "            snName = wstdFile[:7]  # To read correctly, e.g., \"sn2011B_\"\n",
    "        elif wstdFile[7] != '_':\n",
    "            # To read correctly, e.g., \"snf20080514-002\"\n",
    "            if is_number(wstdFile[7]): snName = wstdFile[:15] \n",
    "            else: snName = wstdFile[:8]  # To read correctly, e.g., \"sn1998bu\"  \n",
    "    except: snName = wstdFile[:6]  # To read correctly, e.g., \"sn2011B\"\n",
    "\n",
    "    #-------------------------------\n",
    "\n",
    "    # Create a list of filters that are in a given photometric file:\n",
    "\n",
    "    ListFilters = []\n",
    "    for j in range(len(wstd_np)):\n",
    "\n",
    "        # Read the filter's name\n",
    "        filtername_int_2 = wstd_np['f1'][j]\n",
    "\n",
    "        # Convert the filter's name to SNANA\n",
    "        if filtername_int_2 in filterListToConvert:\n",
    "            filtersnana_2 = FilterNameConversion_dict[filtername_int_2][0]\n",
    "        else:\n",
    "            if write_all_filters:\n",
    "                filtersnana_2 = filtername_int_2\n",
    "\n",
    "        # Create a list of unique filters \n",
    "        if filtersnana_2 not in ListFilters:\n",
    "            ListFilters += [filtersnana_2]\n",
    "\n",
    "    # print '# Filters in this file: ',ListFilters\n",
    "\n",
    "    #---- Create a single string with the name of all the filters ----\n",
    "    # This will be written in the SNANA-format text file \n",
    "    # in the row \"FILTERS: \"\n",
    "\n",
    "    ListFiltersToPrint = ''\n",
    "    for name in ListFilters:\n",
    "        ListFiltersToPrint = ListFiltersToPrint+name\n",
    "\n",
    "    # print '# Text to print in the field FILTERS:', ListFiltersToPrint\n",
    "    \n",
    "    #====================================================\n",
    "    \n",
    "    # Read the time and date right now\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    snana_file = open(DirSaveOutput+wstdFile[:TrimFileName]+'_snana.dat', 'w')\n",
    "\n",
    "    text_line_1 = '#'+'-'*60+'\\n'\n",
    "    snana_file.write('#    %s \\n'%snName)\n",
    "    snana_file.write(\"# Andy Friedman's wstd file converted to SNANA-like format. \\n\")\n",
    "    snana_file.write('# Source file: %s \\n'%wstdFile)\n",
    "    snana_file.write(\"# Metadata information from: %s \\n\"%MetadataFile)\n",
    "    snana_file.write(\"# Located at: \\n\")\n",
    "    snana_file.write(\"# %s \\n\"%DirMetadata)\n",
    "    \n",
    "    snana_file.write(text_line_1)\n",
    "    snana_file.write('# Data table created by: Arturo Avelino \\n')\n",
    "    text_01 = now.strftime(\"%Y-%m-%d (yyyy-mm-dd); %H:%M hrs.\")\n",
    "    snana_file.write('# On date: %s \\n'%text_01)\n",
    "    snana_file.write('# Script used: %s \\n'%NotebookName)\n",
    "    snana_file.write(text_line_1)\n",
    "\n",
    "    #---------------------\n",
    "\n",
    "    #   SNANA header\n",
    "\n",
    "    # Create a final dictionary: \n",
    "    # (snname: zhelio, err_zhelio, zcmb, err_zcmb) \n",
    "    \n",
    "    zhel = InfoSN_dict[snName][0]\n",
    "    err_zhel = InfoSN_dict[snName][1]\n",
    "    \n",
    "    # Flag to determine the appropiate z_cmb:\n",
    "    flag_zcmb  = InfoSN_dict[snName][6]\n",
    "    if flag_zcmb > 0.1:\n",
    "        zcmb     = InfoSN_dict[snName][2]\n",
    "        err_zcmb = InfoSN_dict[snName][3]\n",
    "    else:\n",
    "        zcmb     = InfoSN_dict[snName][4]\n",
    "        err_zcmb = InfoSN_dict[snName][5]\n",
    "\n",
    "    RA       = InfoSN_dict[snName][7]\n",
    "    DEC      = InfoSN_dict[snName][8]\n",
    "    \n",
    "    EBV_MW  = DistMu_dict[snName][2]\n",
    "    PEAKMJD = DistMu_dict[snName][0]\n",
    "\n",
    "    snana_file.write('SURVEY: %s \\n'%Survey)\n",
    "    snana_file.write('SNID: %s \\n'%snName[2:])\n",
    "    snana_file.write('IAUC: %s \\n'%snName[2:])\n",
    "    snana_file.write('RA: %s deg \\n'%RA)\n",
    "    snana_file.write('DECL: %s deg \\n'%DEC)\n",
    "    snana_file.write('MWEBV: %s MW E(B-V) \\n'%EBV_MW)\n",
    "    snana_file.write('REDSHIFT_HELIO: %1.5f +- %1.6f (HEL)\\n'%(zhel, err_zhel))\n",
    "    snana_file.write('REDSHIFT_CMB: %1.5f +- %1.6f (CMB)\\n'%(zcmb, err_zcmb))\n",
    "    snana_file.write('REDSHIFT_FINAL: %1.5f +- %1.6f (CMB)\\n'%(zcmb, err_zcmb))\n",
    "    snana_file.write('SEARCH_PEAKMJD: %.3f \\n'%PEAKMJD)\n",
    "    snana_file.write('FILTERS: %s \\n'%ListFiltersToPrint)\n",
    "\n",
    "    #---------------------\n",
    "\n",
    "    snana_file.write(text_line_1)\n",
    "    snana_file.write('NOBS: %s \\n'%len(wstd_np))\n",
    "    snana_file.write('NVAR: 7 \\n')\n",
    "    snana_file.write('VARLIST:  MJD  FLT           FIELD       \\\n",
    "FLUXCAL         FLUXCALERR  MAG  MAGERR  \\n')\n",
    "\n",
    "    #---------------------\n",
    "\n",
    "    for i in range(len(wstd_np)):\n",
    "\n",
    "        filtername_int1 = wstd_np['f1'][i]\n",
    "\n",
    "        if filtername_int1 in filterListToConvert:\n",
    "            filtersnana = FilterNameConversion_dict[filtername_int1][0]\n",
    "        else: filtersnana = filtername_int1\n",
    "\n",
    "        flux_old         = wstd_np['f2'][i]\n",
    "        err_flux_old_low = wstd_np['f3'][i]\n",
    "        err_flux_old_hig = wstd_np['f4'][i]\n",
    "\n",
    "        flux_new         = flux_snana(flux_old, zp_Andy)\n",
    "        err_flux_new_low = flux_snana(err_flux_old_low, zp_Andy)\n",
    "        err_flux_new_hig = flux_snana(err_flux_old_hig, zp_Andy)\n",
    "\n",
    "        average_errorFlux = (err_flux_new_low + err_flux_new_hig)/2\n",
    "\n",
    "        # Write the line in the text file\n",
    "        snana_file.write('OBS: %.3f  %-12s NULL  %15.4f %15.4f    0     0 \\n'%(wstd_np['f0'][i], \n",
    "                        filtersnana, flux_new, average_errorFlux))\n",
    "\n",
    "    snana_file.write('END:')\n",
    "    snana_file.close();\n",
    "\n",
    "    print wstdFile[0:40]\n",
    "    \n",
    "\n",
    "print '\\n# All the conversion done smoothly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
